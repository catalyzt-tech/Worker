{
  "title": "Experimentation: Impact Metric based voting",
  "content": "This post describes the ongoing experiment of impact metric based voting and\nasks for input and feedback from the community!\n\n\nMETRICS BASED VOTING\n\nCurrently, voting in Retroactive Public Goods Funding (Retro Funding) is made up\nof reviewing and comparing individual applications to come up with an allocation\nof tokens among applicants. This process is intensive in manual labour and\nhighly dependent on the individual experience and expertise of citizens.\nIn recent Retro Funding rounds, Open Source Observer has outlined an alternative\napproach to evaluating impact, by leveraging data to allow citizens express what\ntypes of impact matter most and how they should be rewarded instead of\nrevieweing individual projects.\n\n> Badgeholders are badgeholders because they care deeply about the health and\n> growth of the ecosystem as a whole, not because they know the intricacies of\n> projects. For most badgeholders, evaluating the quality of a portfolio of\n> projects is a much better way of leveraging their time and expertise than\n> evaluating each individual project. This will become even more apparent as the\n> mechanism scales to more projects.\n\nSee @ccerv1 [/u/ccerv1]’s blog posts here\n[https://mirror.xyz/cerv1.eth/tCjpRODfiYpnKIgPLRplW0lAopVP3no_JmI34dNsAWk] and\nOS Observers work on Impact vectors\n[https://mirror.xyz/cerv1.eth/qL9YKLN9-dBzM89qKaZYgHK2ccpZy2XLPz2Z1PObwCg].\n\n\nDIFFERENT TYPES OF IMPACT REQUIRE DIFFERENT MEASUREMENTS\n\nWhile some contributions to Optimism have rich data associated with them, which\nwe can leverage to evaluate impact today, such as onchain contracts and open\nsource libraries, others lack high quality and standardised data for impact\nevaluation, such as IRL events, education initiatives and offchain tooling.\nA metrics based voting experience is only viable for a subset of impact today\nand can’t be applied to evaluate all contributions to the Optimism Collective.\n\n\nIMPACT CALCULATOR: EXPERIMENTING WITH A METRIC BASED VOTING EXPERIENCE\n:seedling: [https://emoji.discourse-cdn.com/twitter/seedling.png?v=12]\n\nTo further explore how citizens could leverage data to evaluate the impact of a\nnumber of projects, we started by putting up a project idea for a prototype of a\nmetric based voting interface called impact calculator\n[https://github.com/ethereum-optimism/ecosystem-contributions/issues/120]. This\nprototype leverages OS Observer [https://www.opensource.observer/] data for\nimpact metrics.\n\n\nBUIDL GUIDL’S PROTOTYPE [https://impact-calculator.vercel.app/]\n\n\n\nScreenshot 2024-02-27 at 15.27.21\n[https://europe1.discourse-cdn.com/bc41dd/optimized/2X/2/215b964f715d09ad6690c6226f50e85b7164febb_2_690x374.png]\nScreenshot 2024-02-27 at 15.27.213024×1642 415 KB\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/2/215b964f715d09ad6690c6226f50e85b7164febb.png]\n\n\n\nVia Buidl Guidl’s Impact Calculator [https://impact-calculator.vercel.app/] a\nuser is able to\n\n 1. Select Impact Vectors: Allows users to choose from various impact vectors\n    (e.g. metrics) with descriptions and creator names, search functionality,\n    and options to view detailed pages or add vectors to a ballot.\n 2. Ballot View: A ballot system where users can select or deselect impact\n    vectors and edit their configurations. This includes a graphical\n    representation of the allocation of OP among projects.\n 3. Detailed View: Each impact vector has a detailed view, including a name,\n    description, creator, and a link to GitHub. Users can visualize the impact\n    vector and configure it.\n 4. Configuration Option: Users can set a scale or weight to deterimine how flat\n    or skewed the eventual distribution of tokens to projects should be.\n\nTLDR; pick what types of impact you think are important and assign weight to\nthem.\n\nRetroPGFhub.com [http://RetroPGFhub.com] is in the early stages of developing\ntheir own version of the impact calculator protoype and will share for input\nonce ready.\n\n\nREQUEST FOR INPUT AND FEEDBACK\n\nAt this early stage input and feedback from the community are very valuable in\nshaping the iteration of this prototype. For the purpose of this prototype we’re\nfocusing on evaluating the impact of onchain deployments and open source\nlibraries.\n\n 1. What are your thoughts on impact metric based voting? What excites you about\n    it or what makes you skeptical?\n 2. What do you think of the current selection of impact vectors? What impact\n    vectors would you want to see to reward onchain deployments/builders?\n 3. Does the weighting help you in expressing what impact you find valuable?\n    Would you want to have additional configuration options?\n 4. Does the graph help you visualize the impact of your impact vector\n    weightings? Do you understand what the graph is showing you? Do you want to\n    see how individual projects are impacted by your weightings?\n\nCheck out the impact calculator here [https://impact-calculator.vercel.app/]\n:point_left: [https://emoji.discourse-cdn.com/twitter/point_left.png?v=12]\nThis thread is used for an open discussion on impact metric based voting and\nwill be used for further updates on the impact calculator prototype.",
  "views": 1554,
  "like_count": 39,
  "word_count": 2010,
  "answer": [
    {
      "content": "\n[https://dub1.discourse-cdn.com/bc41dd/user_avatar/gov.optimism.io/jonas/48/2865_2.png]\nJonas:\n\n\n> DIFFERENT TYPES OF IMPACT REQUIRE DIFFERENT MEASUREMENTS\n> \n> While some contributions to Optimism have rich data associated with them,\n> which we can leverage to evaluate impact today, such as onchain contracts and\n> open source libraries, others lack high quality and standardised data for\n> impact evaluation, such as IRL events, education initiatives and offchain\n> tooling.\n> A metrics based voting experience is only viable for a subset of impact today\n> and can’t be applied to evaluate all contributions to the Optimism Collective.\n\nTo me, this may be the most important point of them all, and I really appreciate\nyou spelling it out here.\n\nWhile for example ‘number of users’ may be an appropriate metric for comparing\notherwise similar analytics services, all of which target highly skilled\ninvestors, it could be a very bad idea to use that same metric indiscriminately\nfor general educational or news services - as that might mean rewarding the most\nattention grabbing or addictive approaches over those that create high quality\ncontent for specific target groups.\n\nIf we want Ether’s Phoenix to be in the service of humanity, we really need to\nthink hard about the relationship between quantitative and qualitative metrics.\n\nA good rule of thumb might be that the more we care about certain qualitative\nmetrics (in the context of certain project categories), the more important it is\nto make sure that they are incorporated into the impact evaluation.\n\nAnd the more a project category targets / affects ‘the whole human’, the more we\nshould probably require subjective human judgement to be a crucial evaluation\ncriteria.\n\nTo the extend that human experience is the goal, human experience should also be\nthe measuring stick.",
      "created_at": "2024-03-07T10:17:57.678Z",
      "trust_level": 2,
      "username": "joanbp",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 6
    },
    {
      "content": "AVOID DIVIDED SYSTEM\n\nI’m concerned about having a divided system, onchain contracts & open source\nlibraries compared with other contributions to OP Stack. For example Gitcoin\ngrants publics good funding is now focusing on open source.\n\nTo avoid this we could look to add categories (e.g. events, education, offchain\ntooling) with metrics that can apply to those categories. e.g. attendees/users,\nfollowers etc\n\nWe could also encourage projects to have onchain & open source components e.g.\nNFTs for attendees/participants, open source repositories for project\ninformation.\n\n\nGAMEABLE METRICS\n\nUnfortunately many of the metrics are gameable.\nEven transaction volume and fees could be gamed with farming for token rewards\nor future token airdrops from projects.\n\nGiven that metrics can be gamed, we should focus on metrics that deliver real\nimpact to the OP stack. RetroPGF is a strong incentive for projects to focus on\nthose impactful metrics.",
      "created_at": "2024-02-29T08:27:53.131Z",
      "trust_level": 2,
      "username": "abcoathup",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 4
    },
    {
      "content": "Great to see this coming into the open. Impact data experiments take us closer\nto a sustainable balance between objective and subjective decision making.\n\nOver time I expect that the variance between human decisions and impact metric\n“ranking” via objective data sources like this to shrink. So rather than answer\nthe questions above, I just want to share one tendency I have seen which is that\ndata (especially in early experiments) can over-correct the way in which people\nrely on their own expertise and contextual knowledge. I’d love to see the impact\nmetrics complement human decision making by providing prompts that help create\nthe right voting habits as well as make better decisions. One very simple\nexample would just be “hey, you didn’t look at the impact metrics… would it help\nyou to review some data?” and more examples of this type would probably create a\nnice loop for early observation of behaviour",
      "created_at": "2024-03-05T06:53:30.855Z",
      "trust_level": 1,
      "username": "b3n",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 4
    },
    {
      "content": "\n[https://dub1.discourse-cdn.com/bc41dd/user_avatar/gov.optimism.io/abcoathup/48/7179_2.png]\nabcoathup:\n\n> Even transaction volume and fees could be gamed with farming for token rewards\n> or future token airdrops from projects.\n\nThis is something I’ve been thinking about quite a lot. It would be very easy\nfor incentives to go very wrong if we focus on metrics like this.\n\nAs an example, lets imagine we give ExampleSwap a grant of xM OP for some\nincentive scheme to attract users (via grant process not retroPGF).\n\nThen that incentive scheme is set up so that users can earn more OP rewards for\nmaking transactions than they spend in ETH for gas.\n\nUsers(/bots) are then effectively paid to use the dApp, and so will pump up\ntransaction numbers even if they aren’t getting any benefit from the swaps\nthemselves.\n\nIf we then weight transaction numbers / gas spent as an important metric for\nassigning RetroPGF we reward ExampleSwap for setting this system up. So they are\nincentivized to use their grants this way…\n\nBut is that actually valuable for Optimism?\n\nQuantifiable metrics can obviously be useful, but if we are not very careful\nthey will be given too much weight, and as you say, gamed to the point of being\nharmful.",
      "created_at": "2024-03-05T09:32:03.264Z",
      "trust_level": 2,
      "username": "MinimalGravitas",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 3
    },
    {
      "content": "Hi @Jonas [/u/jonas] this is 0xR,\n\nImpact metrics have been a huge topic for society and the Optimism Collective. I\nlike to see this experiment of computer-aided decision-making. I believe this is\nessential to make holistic decisions in a scalable way. I tested the prototype\nhere are some questions that came up that could be received as feedback as well.\n\nAs a UI/UX Designer I have some light feedforward on the prototype:\n\n * x & y axis, I did find it hard to understand the x and the y axis of the\n   graph let alone the display of the different OP projects.\n\n * Tool tips, I didn’t understand what I was comparing other projects with and\n   what exactly would fall into an impactful project with the chosen data\n   points. I recommend tooltips to describe certain components/sections better.\n\n * Viewport, The graph seems like the most important component of the page would\n   love to see it larger and more in my face! This could help with the\n   readability of the information that is trying to be visualized/displayed.\n\nSome other questions/answers;\n\nMy biggest skepticism is what is being measured can be easily gamed creating the\nopportunity to create impact farming strategies (might sound cooler than it is).\nSimilar with for example airdrop farming strategies. However, I do believe a\nsolution for this could be created by combining certain on-chain and off-chain\nmetrics Computer/Data-Aided Decisions combined with Human Aided Decisions.\n\nAdd an individual page for projects for a more detailed overview of their\nimpact, Include time as a weighing factor as well. For example, how long has the\nimpact been present?\n\nThis brought up a question;\n\nThe data that is aggregated and analyzed seems like good data points to start\nwith but seems limited to only digital protocols that run on-chain or online.\nAre there any plans to make a similar interface but for projects that leave\nfewer digital breadcrumbs to measure?\n\nIf this tool is just for on-chain builders then go ahead and cancel all feedback\nrelated to off-chain data :pray:\n[https://emoji.discourse-cdn.com/twitter/pray.png?v=12]\n\nHope this helps, Forward we go!\n\nBless 0xR",
      "created_at": "2024-02-27T18:07:00.774Z",
      "trust_level": 2,
      "username": "0xR",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 2
    }
  ],
  "created_at": "2024-02-27T14:46:42.890Z"
}