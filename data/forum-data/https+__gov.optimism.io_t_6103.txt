{
  "title": "[FINAL] Extend the L1Block contract to store historical block hash data",
  "content": "Context: the idea of having historical block hashes stored as part of the\nL1Block contract was previously discussed here\n[https://gov.optimism.io/t/historical-block-hash-as-part-of-the-l1block-contract/6072],\nincluding the proposed technical solution and relevant use cases for it. Thanks\nto @lee0007 [/u/lee0007] for guiding us towards Mission Proposals.\n\nS4 Intent: Collective Intent #1 Progress Towards Techincal Decentralisation\n\nProposed Mission: Extend the L1Block contract to store historical blockhash data\n\nProposal Tier: Ember\n\nPlease verify that you meet the qualifications for your Tier: I am a new\ncommunity member that has not worked with or for the Optimism Collective before\n\nBaseline grant amount: 10k OP\n\n% of total available Intent budget: 1%\n\nAlliance: LimeChain\n\nAlliance Lead: Zhivko Todorov\n\nContact info: @zhivkoto [/u/zhivkoto]\n\nL2 recipient address: 0x6eDf76FD16Bb290A544fDc14fBB4b403D1DEeD9f\n\nPlease list the members of your Alliance and link to any previous work:\n\n * George Spasov, co-founder of LimeChain. Most recently built Extractoor\n   [https://github.com/LimeChain/extractoor-contracts] - Library of contracts\n   used for proving the Merkle Patricia Tree (MPT) inclusion of a certain\n   storage inside a rollup. Co-author of EIP-4400\n   [https://eips.ethereum.org/EIPS/eip-4400], Co-founder of EnterDAO and\n   contributions to many other projects.\n * Daniel Ivanov, Senior Blockchain Architect and R&D at LimeChain. Most\n   recently worked on Wisp\n   [https://ethresear.ch/t/wisp-zk-based-cross-rollup-communication-protocol/15059/2]\n   - cross-rollup communication protocol using ZK proofs (deprecated) and led\n   the research on proving rollups state\n   [https://ethresear.ch/t/proving-rollups-state/15169] (link). Co-author of\n   EIP-4400, Co-founder of EnterDAO and contributions to many other projects.\n * Zhivko Todorov - R&D at LimeChain. Leading governance and ecosystem efforts.\n   Co-founder of EnterDAO.\n\nPlease explain how this Mission will help accomplish the above Intent:\n\n * The addition of historical blockhashes will enable various interoperability\n   use cases. It will allow decentralised, trustless reasoning about the\n   contents of a block - transactions, receipts, state, and more.\n * It will aleviate the pressure of certain use cases to be executed in a small\n   timeframe (1 epoch/L1 block), that currently exists due to the L1Block\n   contract constantly replacing its “current” blockhash.\n\nWhat makes your Alliance well-suited to execute this Mission?\n\n * LimeChain [https://github.com/limechain] is a blockchain development company\n   building blockchain infrastructure and apps since 2017, having worked with\n   companies and organizations such as The Graph, Ledger, Celo, Polkadot,\n   Coinbase and Tally among others.\n   * R&D efforts over the past year heavily focused on contributing to rollups\n     ecosystem. This includes the proof of concept interoperability protocol -\n     Wisp.\n   * The team has collaborated with various projects (building on L2s) on\n     outlining their interoperability requirements.\n\nPlease list a critical milestone. The critical milestone should be a measure of\nwhether you’ve made best efforts to execute what is outlined in this proposal or\nnot. If you fail to achieve your critical milestone, your grant may be clawed\nback.\n\n 1. Milestone “Discovery”: Running at least 5 developer interviews to find out\n    the historical block hashes needs for developers in the OP ecosystem and\n    their relevant use cases. Documenting and publicly sharing notes and use\n    case (if applicable).\n 2. Milestone “Delivery”: Improving the L1Block to support number of historical\n    block hashes. Developing the necessary test cases to ensure maximum code\n    coverage with unit tests\n\nHow should Token House delegates measure progress towards this Mission: These\nshould focus on progress towards completion. Including expected completion dates\nfor each is recommended.\n\n * Developing and committing the data structure to support historical block\n   hashes. (expected completion date 30.06.2023)\n * Developing and committing the necessary getter for historical block hashes by\n   block number. (expected completion date 07.07.2023)\n * Developing and committing the necessary unit tests to reach maximum code\n   coverage (expected completion date 14.07.2023)\n\nHow should badgeholders measure impact upon completion of this Mission? These\nshould be focused on performance and may be used by badgeholders to assess your\nMisson’s impact in the next round of RetroPGF.\n\n * External and internal calls towards the historical block hash data mapping in\n   the L1Block. Ideally this would be measured by on-chain activity, however\n   this would require the contribution of an on-chain analytics module which, as\n   a scope would be larger than this grant alone. For now we plan on paying\n   attention to major cross-chain projects as they come and their codebase for\n   the usage of the historical block hash information.\n\nBreakdown of Mission budget request:\n\nTotal Mission budget request: 10,000 OP\n\n * Milestone Discovery: 2,500 OP\n * Milestone Development: 7,500 OP\n\nI confirm that my grant will be subject to clawback for failure to execute on\ncritical milestones: Yes\n\nI confirm that I have read and understand the grant policies\n[https://gov.optimism.io/t/token-house-grant-policies/5833]: Yes\n\nI understand that I will be required to provide additional KYC information to\nthe Optimism Foundation to receive this grant: Yes\n\nI understand that I will be expected to following the public grant reporting\nrequirements outlined here\n[https://gov.optimism.io/t/suggested-public-reporting-requirements-for-grantees/4176]:\nYes",
  "views": 2878,
  "like_count": 78,
  "word_count": 3754,
  "answer": [
    {
      "content": "Hey @zhivkoto [/u/zhivkoto], thanks for the proposal. I am a contributor to the\nOptimism Collective and speak on behalf of my own opinions.\n\nI generally like this idea and think it could be implemented in a fairly\nstraight forward way. A ringbuffer library could be implemented over a fixed\nsize array. This keeps the storage overhead at a constant size. As each new L1\norigin is adopted, it could append to this ringbuffer. To make it useful, we\nwould need a “get blockhash by L1 blocknumber” API. This API could revert if the\nblocknumber doesn’t exist in the ring buffer (slight preference over returning\nbytes32(0) to prevent footguns). We would need some sort of global variable\nrepresenting blocknumber offset so that we can index into the ringbuffer given\nan L1 blocknumber.\n\nDoes this make sense and would this work for your usecase?\n\nIf so, some things to derisk this would be coming to consensus on how large of a\nringbuffer would be nice. How much history do you need? What sort of impact on\nthe DB size would this have? Also the rollout to the network is critical.\nIdeally the rollout can happen in a way where it does not matter what L2 block\nthe proxy is upgraded in. Also this should require no op-node changes.",
      "created_at": "2023-06-15T22:04:46.022Z",
      "trust_level": 2,
      "username": "tynes",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 4
    },
    {
      "content": "It should be marked [DRAFT] until it has received the 4 required delegate\napprovals, as outlined in operating manual\n[https://github.com/ethereum-optimism/OPerating-manual/blob/main/manual.md]",
      "created_at": "2023-06-20T12:36:02.365Z",
      "trust_level": 4,
      "username": "lavande",
      "admin": true,
      "moderator": true,
      "staff": true,
      "like_count": 3
    },
    {
      "content": "Thank you for taking my suggestions to heart! I get that you might not be able\nto measure the calls quantitatively, and that’s okay. Figuring out a way to\ndisplay the impact your mission will have after its completion will help you\nnominate yourself for RPGF since badge holders will need it.\n\nAgain, great job overall though!",
      "created_at": "2023-06-19T16:19:33.600Z",
      "trust_level": 2,
      "username": "Sinkas",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 3
    },
    {
      "content": "> I’d definitely consider a mixture between Solidity and assembly (Yul could be\n> an overkill too :smiley:\n> [https://emoji.discourse-cdn.com/twitter/smiley.png?v=12] )\n\nFor what its worth, solidity assembly is yul. I don’t recommend writing this in\nstraight yul. Another requirement is that the storage layout of the L1Block\ncontract cannot change as well as the existing API. I think the best way to\nensure this is to implement a fixed size array directly in the L1Block contract\nthat is internal. Writing it as a library could make it easier to test in\nisolation, although I would be curious about the bytecode that it generates vs\njust implementing the logic directly in the contract. You shouldn’t need to ever\ndelete elements, just overwrite them in place.\n\n> what is the general advice on auditing this mission deliverable\n\nThe smart contract team can review your code, use the existing tests as a guide.\nIt is important that test cases are covered such as:\n\n * rollaround overwrites first element\n * reverts on out of bounds (example: blocks 10 to 50 are in the ring buffer,\n   try to get block 9)\n * not full buffer yet, reverts on getting a block that could be in there but is\n   in the future\n\nRegarding an official audit, we will determine based on factors such as how well\ntested the code is and how easy it is to read.\n\nSome example code that definitely is not sufficient for the real thing:\n\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.17;\n\nlibrary RingBuffer {\n    function get(bytes32[128] storage _hashes, uint256 _number) internal view returns (bytes32) {\n        return _hashes[_number % 128];\n    }\n\n    function set(bytes32[128] storage _hashes, uint256 _number, bytes32 _hash) internal {\n        _hashes[_number % 128] = _hash;\n    }\n}\n\ncontract L1Block {\n    using RingBuffer for bytes32[128];\n    bytes32[128] internal _hashes; \n\n    function foo() public {\n        _hashes.set(1, bytes32(uint256(1)));\n\n        bytes32 hash = _hashes.get(1);\n\n        require(hash == bytes32(uint256(1)));\n    }\n}\n\n\nI’m curious about using storage fixed size arrays in libraries, what sort of\nbytecode gets generated and how that looks compared to just using all internal\nfunctions in the L1Block contract directly.",
      "created_at": "2023-06-22T19:15:22.932Z",
      "trust_level": 2,
      "username": "tynes",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 3
    },
    {
      "content": "I am an Optimism delegate [Delegate Commitments - #65 by mastermojo\n[https://gov.optimism.io/t/delegate-commitments/235/65]] with sufficient voting\npower, and I believe this proposal is ready to move to a vote.",
      "created_at": "2023-06-26T12:13:43.349Z",
      "trust_level": 2,
      "username": "mastermojo",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 3
    }
  ],
  "created_at": "2023-06-14T13:58:26.771Z"
}