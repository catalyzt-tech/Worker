{
  "title": "OPML: Optimistic Machine Learning on Blockchain, an efficient on-chain AI approach",
  "content": "TL;DR\n\n * We propose OPML (Optimistic Machine Learning), which enables AI model\n   inference on the blockchain system using optimistic approach (OPML is also\n   called FPML, where “FP” refers to fraud proof).\n * OPML can provide ML service with low cost and high efficiency compared to\n   ZKML. The participation requirement for OPML is low: We are now able to run\n   OPML with a large language model, e.g., 7B-LLaMA (the model size is around\n   26GB) on a common PC without GPU.\n * OPML adopts a verification game (similar to Truebit and Optimistic Rollup\n   systems) to guarantee decentralized and verifiable consensus on the ML\n   service.\n   * The requester first initiates an ML service task.\n   * The server then finishes the ML service task and commits results on chain.\n   * The verifier will validate the results. Suppose there exists a verifier who\n     declares the results are wrong. It starts a verification game with\n     verification game (dispute game) with the server and tries to disprove the\n     claim by pinpointing one concrete erroneous step.\n   * Finally, arbitration about a single step will be conducted on smart\n     contract.\n * OPML is still under development, and is open-sourced: OPML-Labs/opml: OPML:\n   OPtimistic Machine Learning on Blockchain (github.com)\n   [https://github.com/OPML-Labs/opml]\n\n\nSINGLE-PHASE VERIFICATION GAME\n\nThe one-phase pinpoint protocol works similarly to referred delegation of\ncomputation (RDoC), where two or more parties (with at least one honest party)\nare assumed to execute the same program. Then, the parties can challenge each\nother with a pinpoint style to locate the disputable step. The step is sent to a\njudge with weak computation power (smart contract on blockchain) for\narbitration.\n\nIn one-phase OPML:\n\n * We build a virtual machine (VM) for off-chain execution and on-chain\n   arbitration. We guarantee the equivalence of the off-chain VM and the\n   on-chain VM implemented on smart contract.\n * To ensure the efficiency of AI model inference in the VM, we have implemented\n   a lightweight DNN library specifically designed for this purpose instead of\n   relying on popular ML frameworks like Tensorflow or PyTorch. Additionally, a\n   script that can convert Tensorflow and PyTorch models to this lightweight\n   library is provided.\n * The cross-compilation technology has been applied to compile the AI model\n   inference code into the VM program instructions.\n * The VM image is managed with a Merkle tree, only the Merkle root will be\n   uploaded to the on-chain smart contract. (the Merkle root stands for the VM\n   state)\n * The bisection protocol will help to locate the dispute step, the step will be\n   sent to the arbitration contract on the blockchain\n\nPerformance: We have tested a basic AI model (a DNN model for MNIST\nclassification) on a PC. We are able to complete the DNN inference within 2\nseconds in the VM, and the entire challenge process can be completed within 2\nminutes in a local Ethereum test environment.\n\n\nMULTI-PHASE VERIFICATION GAME\n\n\nLIMITATIONS OF ONE-PHASE PINPOINT PROTOCOL\n\nThe one-phase verification game has a critical drawback: all computations must\nbe executed within the Virtual Machine (VM), preventing us from leveraging the\nfull potential of GPU/TPU acceleration or parallel processing. Consequently,\nthis restriction severely hampers the efficiency of large model inference, which\nalso aligns with the current limitation of the referred delegation of\ncomputation (RDoC) protocol.\n\n\nTRANSITIONING TO A MULTI-PHASE PROTOCOL\n\nTo address the constraints imposed by the one-phase protocol and ensure that\nOPML can achieve performance levels comparable to the native environment, we\npropose an extension to a multi-phase protocol. With this approach, we only need\nto conduct the computation in the VM only in the final phase, resembling the\nsingle-phase protocol. For other phases, we have the flexibility to perform\ncomputations that lead to state transitions in the native environment,\nleveraging the capabilities of CPU, GPU, TPU, or even parallel processing. By\nreducing the reliance on the VM, we significantly minimize overhead, resulting\nin a remarkable enhancement in the execution performance of OPML, almost akin to\nthat of the native environment.\n\nThe following figure demonstrates a verification game consists of two phases (k\n= 2). In Phase-1, the process resembles that of a single-phase verification\ngame, where each state transition corresponds to a single VM microinstruction\nthat changes the VM state. In Phase-2, the state transition corresponds to a\n“Large Instruction” encompassing multiple microinstructions that change the\ncomputation context.\n\nThe submitter and verifier will first start the verification game on Phase-2\nusing bisection protocol to locate the dispute step on a “large instruction”.\nThis step will be send to the next phase, Phase-1. Phase-1 works like the\nsingle-phase verification game. The bisection protocol in Phase-1 will help to\nlocate the dispute step on a VM microinstruction. This step will be sent to the\narbitration contract on the blockchain.\n\nTo ensure the integrity and security of the transition to the next phase, we\nrely on the Merkle tree. This operation involves extracting a Merkle sub-tree\nfrom a higher-level phase, thus guaranteeing the seamless continuation of the\nverification process.\n\n\n\nmulti-phase\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/f/ff6b988465205d59c18b1c88320486dae455d765.png]\nmulti-phase651×585 17 KB\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/f/ff6b988465205d59c18b1c88320486dae455d765.png]\n\n\n\n\nMULTI-PHASE OPML\n\nIn this demonstration, we present a two-phase OPML approach, as utilized in the\nLLaMA model:\n\n * The computation process of Machine Learning (ML), specifically Deep Neural\n   Networks (DNN), can be represented as a computation graph denoted as $G$.\n   This graph consists of various computation nodes, capable of storing\n   intermediate computation results.\n\n * DNN model inference is essentially a computation process on the\n   aforementioned computation graph. The entire graph can be considered as the\n   inference state (computation context in Phase-2). As each node is computed,\n   the results are stored within that node, thereby advancing the computation\n   graph to its next state.\n\n * Therefore, we can first conduct the verification game on the computation\n   graph (At phase-2). On the phase-2 verification game, the computation on\n   nodes of the graph can be conducted in native environment using multi-thread\n   CPU or GPU. The bisection protocol will help to locate the dispute node, and\n   the computation of this node will be sent to the next phase (phase-1)\n   bisection protocol.\n\n * In Phase-1 bisection, we transform the computation of a single node into\n   Virtual Machine (VM) instructions, similar to what is done in the\n   single-phase protocol.\n\nIt is worth noting that we anticipate introducing a multi-phase OPML approach\n(comprising more than two phases) when the computation on a single node within\nthe computation graph remains computationally complex. This extension will\nfurther enhance the overall efficiency and effectiveness of the verification\nprocess.\n\n\nPERFORMANCE IMPROVEMENT\n\nHere, we present a concise discussion and analysis of our proposed multi-phase\nverification framework.\n\nSuppose there are $n$ nodes in the DNN computation graph, and each node needs to\ntake $m$ VM microinstructions to complete the calculation in VM. Assuming that\nthe speedup ratio on the calculation on each node using GPU or parallel\ncomputing is $\\alpha$. This ratio represents the acceleration achieved through\nGPU or parallel computing and can reach significant values, often ranging from\ntens to even hundreds of times faster than VM execution.\n\nBased on these considerations, we draw the following conclusions:\n\n 1. Two-phase OPML outperforms single-phase OPML, achieving a computation\n    speedup of $\\alpha$ times. The utilization of multi-phase verification\n    enables us to take advantage of the accelerated computation capabilities\n    offered by GPU or parallel processing, leading to substantial gains in\n    overall performance.\n 2. Two-phase OPML reduces space complexity of the Merkle tree. When comparing\n    the space complexity of the Merkle trees, we find that in two-phase OPML,\n    the size is $O(m + n)$, whereas in single-phase OPML, the space complexity\n    is significantly larger at $O(mn)$. The reduction in space complexity of the\n    Merkle tree further highlights the efficiency and scalability of the\n    multi-phase design.\n\nIn summary, the multi-phase verification framework presents a remarkable\nperformance improvement, ensuring more efficient and expedited computations,\nparticularly when leveraging the speedup capabilities of GPU or parallel\nprocessing. Additionally, the reduced Merkle tree size adds to the system’s\neffectiveness and scalability, making multi-phase OPML a compelling choice for\nvarious applications.\n\n\nCONSISTENCY AND DETERMINISM\n\nIn OPML, ensuring the consistency of ML results is of paramount importance.\n\nDuring the native execution of DNN computations, especially across various\nhardware platforms, differences in execution results may arise due to the\ncharacteristics of floating-point numbers. For instance, parallel computations\ninvolving floating-point numbers, such as $(a + b) + c$ versus $a + (b + c)$,\noften yield non-identical outcomes due to rounding errors. Additionally, factors\nsuch as programming language, compiler version, and operating system can\ninfluence the computed results of floating-point numbers, leading to further\ninconsistency in ML results.\n\nTo tackle these challenges and guarantee the consistency of OPML, we employ two\nkey approaches:\n\n 1. Fixed-point arithmetic, also known as quantization technology, is adopted.\n    This technique enables us to represent and perform computations using fixed\n    precision rather than floating-point numbers. By doing so, we mitigate the\n    effects of floating-point rounding errors, leading to more reliable and\n    consistent results.\n 2. We leverage software-based floating-point libraries that are designed to\n    function consistently across different platforms. These libraries ensure\n    cross-platform consistency and determinism of the ML results, regardless of\n    the underlying hardware or software configurations.\n\nBy combining fixed-point arithmetic and software-based floating-point libraries,\nwe establish a robust foundation for achieving consistent and reliable ML\nresults within the OPML framework. This harmonization of techniques enables us\nto overcome the inherent challenges posed by floating-point variations and\nplatform disparities, ultimately enhancing the integrity and dependability of\nOPML computations.\n\n\nOPML VS ZKML\n\nOPML ZKML model size any size (available for extremely large model)\nsmall/limited (due to the cost of ZKP generation) validity proof fraud proof\nzero-knowledge proof (ZKP) training support* √ × requirement Any PC with CPU/GPU\nLarge memory for ZK circuit Finality Delay for challenge period No delays\nservice cost low (inference and training can be conducted in native environment)\nextremely high (generating a ZKP for ML inference is extremely high) security\ncrypto-economic incentives for security cryptographic security\n\n*: Within the current OPML framework, our primary focus lies on the inference of\nML models, allowing for efficient and secure model computations. However, it is\nessential to highlight that our framework also supports the training process,\nmaking it a versatile solution for various machine learning tasks.\n\nNote that OPML is still under development. If you are interested in becoming\npart of this exciting initiative and contributing to the OPML project, please do\nnot hesitate to reach out to us.",
  "views": 725,
  "like_count": 1,
  "word_count": 1761,
  "answer": [],
  "created_at": "2023-08-04T14:46:53.607Z"
}