{
  "title": "[DRAFT][GF: Phase 1 Proposal Cycle 7] GPUX",
  "content": "Project Name: GPUX (https://gpux.ai/ [https://gpux.ai/])\nProject Type: Infrastructure, Marketplace\n\nAuthor Name: vans163 (@van163 TG)\n\nI understand that I will be required to provide additional KYC information to\nthe Optimism Foundation to receive this grant: Yes\n\nL2 Recipient Address: vans163.eth\n\nWhich Voting Cycle are you applying for?: Cycle 7\n\nGrant category:\n\nIs this proposal applicable to a specific committee? No\n\nProject Description (please explain how your project works):\nWe create a decentralised protocol (think IPFS) to connect GPU providers\n(ex-miners, onprem labs, etc) with GPU consumers (Midjourney inference/training,\nother AI Art, AI training, AI inference, blender animation rendering, etc).\n\nIn a post-merge world this creates a cost savings of 66-95% for GPUs compared to\ncentralised clouds.\n\nProject links:\n\n * Website: https://gpux.ai/ [https://gpux.ai/]\n * Twitter: https://twitter.com/gpux_ai [https://twitter.com/gpux_ai]\n * Discord/Discourse/Community: gpuedge [https://discord.com/invite/jjBSjSF]\n * Please include all other relevant links below:\n\nPlease link to any previous projects the team has meaningfully contributed to:\nNEAR Protocol\n\ngithub.com/near/near-sdk-as [https://github.com/near/near-sdk-as/pull/688]\n\nADD RNG XORSHIFT128P [https://github.com/near/near-sdk-as/pull/688]\n\nnear:master ← checkgpu:xorshift128p\nopened 04:02PM - 19 Jan 22 UTC\nvans163\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/6/676276005ad02649687cc3346fb3a0ceb98ec57b.png]\nvans163 [https://github.com/vans163]\n+57 -1 [https://github.com/near/near-sdk-as/pull/688/files]\n\nAdd a lite RNG implementation that does not write to contract storage each time.\n\n\n\ngithub.com/near/near-sdk-as [https://github.com/near/near-sdk-as/issues/690]\n\nPOTENTIALLY LOOK AT USING NATIVEMATH SEEDRANDOM\n[https://github.com/near/near-sdk-as/issues/690]\n\nopened 04:06PM - 20 Jan 22 UTC\nvans163\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/6/676276005ad02649687cc3346fb3a0ceb98ec57b.png]\nvans163 [https://github.com/vans163]\nenhancement T-dev-tools\n\n[https://github.com/AssemblyScript/assemblyscript/pull/2053/files](https://githu…b.com/AssemblyScript/assemblyscript/pull/2053/files)\nPotentially look at implementing NativeMath seedRandom and seeding it with the\nrandomSeed we get off the vrf.\n\n\n\ngithub.com/near/near-sdk-as [https://github.com/near/near-sdk-as/issues/548]\n\nF64 DOES NOT COMPILE [https://github.com/near/near-sdk-as/issues/548]\n\nopened 06:31PM - 18 May 21 UTC\nclosed 08:41PM - 18 May 21 UTC\nvans163\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/6/676276005ad02649687cc3346fb3a0ceb98ec57b.png]\nvans163 [https://github.com/vans163]\nbug\n\nA few cases where f64 does not compile ``` near-sdk-as@^3.0.0: version \"3….1.0\"\nresolved\n\"https://registry.yarnpkg.com/near-sdk-as/-/near-sdk-as-3.1.0.tgz#b1273ff6283bfe119ac51f9953d8d774d691d0ec\"\nintegrity\nsha512-31ZwYwTyPaiG7FFXGWU2u8i5l1ak0BwZCiMLdj0JIpiW4suI+hYN4PXCIf92prAAFD8HTJ5oMdsKKi3bLRwQDQ==\ndependencies: near-mock-vm \"^3.1.0\" near-sdk-bindgen \"^3.1.0\" near-sdk-core\n\"^3.1.0\" near-sdk-simulator \"^3.1.0\" ``` ``` let total_minted2 =\nstorage.get<f64>(\"zod_minted\", 0.0)! ERROR AS204: Type 'f64' cannot be nullable.\nstatic get<T>(key: string, defaultValue: T | null = null): T | null { ~ in\n~lib/near-sdk-core/storage.ts(178,44) ``` ``` let total_minted2 =\nstorage.get<f64>(\"zod_minted\") ERROR AS204: Type 'f64' cannot be nullable.\nstatic get<T>(key: string, defaultValue: T | null = null): T | null { ~ in\n~lib/near-sdk-core/storage.ts(178,44) ``` ``` total_minted: u128 = \"10000000..\"\n(total_minted as f64) * 0.01 ERROR TS2757: Type\n'~lib/as-bignum/integer/safe/u128/u128' has no call signatures. let total_minted\n= storage.get<u128>(\"zod_minted\", u128.Zero)!(total_minted as f64) * 0.01;\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ in\nassembly/index.ts(96,22) ```\n\n\n\ngithub.com/near/nearcore [https://github.com/near/nearcore/issues/4462]\n\nSTATE CHANGES AKA EVENTS FOR CLIENTS\n[https://github.com/near/nearcore/issues/4462]\n\nopened 03:33PM - 06 Jul 21 UTC\nclosed 02:15PM - 23 Nov 21 UTC\nvans163\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/6/676276005ad02649687cc3346fb3a0ceb98ec57b.png]\nvans163 [https://github.com/vans163]\nC-enhancement A-transaction-runtime T-public-interfaces\n\nSo https://github.com/near/nearcore/issues/1546 was closed but it misses the\nmai…n point, clients need a way to subscribe to events on a smart contract. Its\na very common use case to constantly check for changes when >1 parties are\ninvolved where polling constantly on sides is not an option. Neither is it an\noption for these clients to run full nodes locally, someone might be on their\niPhone browser. We currently are using a off chain provider to handle our\nevents, we could move a lot more to onchain if we were able to have clients\nreact in real time to changes via event subscriptions.\n\n\n\n[https://github.githubassets.com/favicons/favicon.svg] GitHub\n[https://github.com/vans163/NCD-05--offchain-auth]\n[https://europe1.discourse-cdn.com/bc41dd/optimized/2X/f/f108e093e16d27d8280100b20a3491164041fd33_2_690x345.png]\n\n\nGITHUB - VANS163/NCD-05--OFFCHAIN-AUTH\n[https://github.com/vans163/NCD-05--offchain-auth]\n\nContribute to vans163/NCD-05--offchain-auth development by creating an account\non GitHub.\n\n\n\n\nRelevant Usage Metrics: Transactions for compute, Deposits by consumers, Payouts\nto providers, total compute power in network, total unique accounts\n\nOptimism native: No\n\nDate of deployment/expected deployment on Optimism: After start of OP\nGPU-provider/ecosystem-app incentive program\n\nEcosystem Value Proposition:\n\n * What is the problem statement this proposal hopes to solve for the Optimism\n   ecosystem?\n\n * New category of DApps can be built, imagine AI Art (diffusion) NFT minting,\n   the diffusion inference can happen on GPUX instead of the AWS/GCP Cloud.\n\n * How does your proposal offer a value proposition solving the above problem?\n\n * By providing the infrastructure or “layer0” to run said functionality\n   required by next gen DApps on top of.\n\n * Why will this solution be a source of growth for the Optimism ecosystem?\n\n * Marketplaces in-general produce very high growth once functional. Demand for\n   GPUs is growing fast with breakthroughs in AI (diffusion, NLP, reinforcement\n   learning, robotics). ETH just left equivalent of 5m 3090ti without work.\n\nHas your project previously applied for an OP grant? No\n\nNumber of OP tokens requested: 300,000\n\nDid the project apply for or receive OP tokens through the Foundation Partner\nFund?: No\n\nProposal for token distribution:\nHow will the OP tokens be distributed?\n\n * a. 17% Engineering\n   This is for our core team engineers and trusted compute (SGX) team (which is\n   on contract)\n * b. 33% Early adopter App Builder incentive\n   This is for builders incentive building apps on GPUX, apps can be similar to\n   StableDiffusions, Reface, GigapixelAI, GPT3, etc.\n * c. 17% Marketting/Community\n   So people learn about and know what GPUX is. That it exists.\n * d. 33% Early adopter Node Incentive (fold protein to cure alzheimer’s / train\n   AI to help good causes)\n   To bootstrap farming nodes (computers with GPUs) we want to create our own\n   jobs for the greater good, like protein folding. This means we dont need a 2\n   sided market (with users and farmers, we can bootstrap the user side via this\n   incentive pool. NEARCrowd uses similar model providing the reward to earners\n   from their staked NEAR)\n\nOver what period of time will the tokens be distributed?\n\n * a. 18 mon.\n * b. As users build on the platform (6-18 mon) (we want to host a few\n   hackathons + partner with education company to teach how to build)\n * c. 18 mon. Everyone in crypto should know atleast that GPUX exists by 18\n   months.\n * d. Linked to b., the quicker b adopts the quicker we will distribute d. But\n   in-order for b. to adopt we need to incentivise via d.\n\nPlease list the milestones/KPIs you expect to achieve for each initiative:\n\n * a. Elixir SDK, JS SDK, Node Explorer /w Simple HTTP API (no need to integrate\n   SDK yourself similar to using INFURA nodes)\n * b. Individual milestones which each builder, have their apps hit 10 | 100 |\n   10_000 | 1m txs per day.\n * c. Twitter scores and other marketting reach KPIs\n * d. Node Stability, Node is honest about its capacity\n\nHow will this distribution incentivize usage and liquidity on Optimism?\n\n * Early node incentives will make it profitable to connect hardware to\n   GPUX even if the consumer side is not fully saturated.\n * Every transaction for shortterm compute will go through optimism, including\n   the followup\n   refund.\n\nExample: A user requests 3 nodes and take 32cpucores, 128gb ram and 4 gpus from\neach. For a total of 96 cores, 384G ram, 12 gpus. They realize they need more\ntime and topup their deposit for an extra 3 hours. After they finish training\ntheir neural network they request a deposit refund from the node providers.\nTotal OP transactions 9. 1 tx to each node provider with deposit (3 total), 1tx\nto each node provider for topup (3+3 total). Each node provider back to the user\nwith their refund (3+3+3 total).\n\nWhy will the incentivized users and liquidity remain after incentives dry up?\n\n * The marketplace just needs to get rolling with both sides. Users will see how\n   good\n   the experience on GPUX is and they will not leave. Find us a platform you\n   would use over\n   GPUX for your spot gpu tasks and we will innovate to make said task\n   impossible.\n\nStable Diffusion Example (One of the many apps that may be built on top of\nGPUX):\n\n(In the future the Node Explorer will have a much nicer UX. Because each node is\ndecentralized+independent this is the UI when you directly visit a node)\n\nhttps://video0.gpux.ai/api/file/download/r2mptm56fo1g1v53p39h161qd6q13djch9oq03psltiv7vjsorl0.mp4\n[https://video0.gpux.ai/api/file/download/r2mptm56fo1g1v53p39h161qd6q13djch9oq03psltiv7vjsorl0.mp4]",
  "views": 2245,
  "like_count": 8,
  "word_count": 2457,
  "answer": [
    {
      "content": "Just checking in to see if you would like this proposal to be evaluated in\nVoting Cycle #6 according to the updated grant proposal template\n[https://gov.optimism.io/t/grant-proposal-template/3233/15]?",
      "created_at": "2022-09-13T21:34:45.670Z",
      "trust_level": 4,
      "username": "lavande",
      "admin": true,
      "moderator": true,
      "staff": true,
      "like_count": 1
    },
    {
      "content": "You can move back to DRAFT for now. Here is how the next voting cycle will work:\n\nWeek 1 (9/29-10/5): Community Feedback\nWeek 2 (10/6-10/12): Delegate Review (here is when you’ll need to get the 2\napprovals)\nWeek 3 (10/13-10/19): Voting\n\nSo delegates are not likely to review your proposal until the week of 10/6\n(although they may sooner, if they have extra time). At that time, the best way\nto get in touch with delegates directly is in the governance channels in our\nDiscord :slight_smile:\n[https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12]",
      "created_at": "2022-09-21T21:15:43.278Z",
      "trust_level": 4,
      "username": "lavande",
      "admin": true,
      "moderator": true,
      "staff": true,
      "like_count": 1
    },
    {
      "content": "This is clearly a very interesting use case of a decentralized network using\nGPUs to solve a real computing problem.\nMy concerns: you aim to be a super planetary computer formed by decentralized\nnodes with no central point of failure. I guess you are aware of the difficulty\nof this.\n\nAre you familiar with the Proof of useful work concept? I think it is an open\nproblem with no proof solution running successfully. I will love to explore this\nproblem, but in this case, there has to be (at first) a central authority\nverifying the amount of computing power any node is contributing to the network.\nPlease correct me if I am wrong in this.\n\nThanks and good luck with the proposal",
      "created_at": "2022-10-02T20:34:37.676Z",
      "trust_level": 2,
      "username": "TheDoctor",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 1
    },
    {
      "content": "\n[https://avatars.discourse-cdn.com/v4/letter/v/5f9b8f/48.png] vans163:\n\n> hy you use AWS or Hetzner or\n\nThank you so much for your explanation.\nI love this kind of idea, especially after the merge. In my opinion, there is no\nfuture in keeping wasting GPU mining in a non-relevant PoW chain. So I started\nto look into Proof of Useful work but is highly technical and I need more time\nto read. Anyway, as far as I understand it is more plausible a reputation\napproach, and this could be centralized at first, and eventually a DAO could\ntake control.\n\nApart from the PoUW holy grail, creating a decentralized storage network or\ncloud computing is not easy or trivial: IPFS is the most popular p2p solution,\nbut it has some issues when you need an upgradable BBDD.\nStorage: Filecoin using IPFS (interesting but with limited use) or Chia creating\na proof of space system (I didn’t like this approach)\nCloud Computing and more similar to this project:\nhttps://internetcomputer.org/ [https://internetcomputer.org/] → They sold a\ngreat number of tokens and investors felt scammed.\nhttps://fluxwhitepaper.app.runonflux.io/\n[https://fluxwhitepaper.app.runonflux.io/] → Need to learn more about it\n\nTo sum up. I love this project, so much potential. Tech is complicated, but my\nmain concern is how to create trust. We have already seen the problem of\ninventing a tokenomic giving ilusion of decentralisation and ending up as a\npiramide scam, I need to hear about a different aproach. I like that you are\nthinking in a stable con for payment, there’s no need for a token there and most\nprojects mix concepts.\n\nI look forward to hearing from this poject and other community feedback\nBest wishes\nPD:\nSome papers about proof of useful work:\n\n[https://europe1.discourse-cdn.com/bc41dd/original/2X/d/d5f62c8431fdf5bf6f32544382145d138be3f23c.png]\nPubMed Central (PMC) [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515252/]\n[https://europe1.discourse-cdn.com/bc41dd/optimized/2X/1/1c2b2fab27273d4bb02dc0a9b2efa3389fa20ffe_2_690x360.jpeg]\n\n\nCOIN.AI: A PROOF-OF-USEFUL-WORK SCHEME FOR BLOCKCHAIN-BASED DISTRIBUTED DEEP...\n[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515252/]\n\nOne decade ago, Bitcoin was introduced, becoming the first cryptocurrency and\nestablishing the concept of “blockchain” as a distributed ledger. As of today,\nthere are many different implementations of cryptocurrencies working over a\nblockchain, ...\n\n\n\n\nhttps://iohk.io/en/blog/posts/2022/08/16/introducing-ofelimos-a-proof-of-useful-work-consensus-protocol/\n[https://iohk.io/en/blog/posts/2022/08/16/introducing-ofelimos-a-proof-of-useful-work-consensus-protocol/]\nhttps://www.sciencedirect.com/science/article/pii/S2096720922000306\n[https://www.sciencedirect.com/science/article/pii/S2096720922000306]",
      "created_at": "2022-10-03T08:03:45.474Z",
      "trust_level": 2,
      "username": "TheDoctor",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 1
    },
    {
      "content": "The points of failure would be similar to IPFS, BGP can go down, DNS can go\ndown, node operators network can go down, nodes will be unreachable in that\ncase. When saying central point of failure I meant there is no central backend\n(openstack, kubes, proxmox, gcp, aws, etc) tied to all the nodes (that spins\nup/down nodes, calculates billing or does other things).\n\nAbout PoUW, I was not aware but I quickly read up a bit about it, as a\nfirst-timer hearing about it I would ask :\n\n(most important) How is work verified to be useful. If its validated somehow\ndeterministically, decimal operations like AI weights+biases will not verify\ncorrectly in 100% of cases depending on underlying hardware/software (and how it\nhandles decimal ops).\n\nOur approach is to proof usefulness of work by reputation, similar to why you\nuse AWS or Hetzner or NicheCompanyB, because you found their service very good\nor were recommended (or got 150k$ credits and couldn’t say no :P). Cant we bring\nthis reputation on-chain where community governs the node operators\nautonomously, advertise a RTX3090 but train the model at the speed of a RTX3060,\nreputation goes down (or simply does not go up). There are multiple approaches\nto this and I have not read any relevant material tackling it yet (fisherpeople,\narbiters, point scoring, etc).\n\nAbout the “central authority verifying the amount of computing power any node is\ncontributing (at first)”, the BDFL path is the least pain so yes. There does\nneed to be an authority issuing some kind of reputation at least /w possible\ncertification (100% renewable energy mix, Tier4 DataCenter, etc). With a DAO\nrunning that can be the DAO but at the early BDFL stage of a project that would\nmost likely be GPUX itself to bootstrap the ecosystem.\n\n(one approach, the scoring approach) The authority is not really verifying that\nyour RTX3090 does the work a RTX3090 should do, its simply giving you reputation\nas you receive payments and potentially verifying your physical location Tier4\nDC or say carbon mix (example nodes hosted with hetzner will be certified 100%\nrenewable\nhttps://www.hetzner.com/assets/Uploads/Oomi-sertifikaatti-tuuli+vesi-Hetzner-2022-eng.pdf\n[https://www.hetzner.com/assets/Uploads/Oomi-sertifikaatti-tuuli+vesi-Hetzner-2022-eng.pdf]).\nWe can enforce this by the organization hosting the nodes (mom-n-pop, basement\nlab, Hetzner, etc) signing their nodes with their pubkey, then we assign the\ncertifications to the organization. Then its just a simply lookup to get the\nrep+assigned credentials.\n\n(another approach the fisher/arbiter) This approach would indeed perhaps have a\nteam of crafty individuals running sneaky jobs that prop for caps of the host,\nif the host is not providing service as advertised they can start arbitration vs\nthe host until the quality is returns to standard. For their work they get a\nslash of the hosts earnings for example. But this system would be much more\ncomplex.",
      "created_at": "2022-10-03T01:03:02.153Z",
      "trust_level": 1,
      "username": "vans163",
      "admin": false,
      "moderator": false,
      "staff": false,
      "like_count": 1
    }
  ],
  "created_at": "2022-06-20T18:18:58.224Z"
}