{
  "title": "Proving the RetroPGF Results",
  "content": "We are from the team at EZKL, and developers of the open EZKL library which\ngenerates zero knowledge proofs for algorithms, data science models, and machine\nlearning models.\n\nIn the past few weeks, we’ve been working to prove correctness of the\nRetroactive Public Goods Funding results. We’ve piloted the proof with Round 3.\nThis post intends to explain the mechanics of the audit and also ask for\nfeedback from the Optimism community.\n\nThe TLDR;\n\n * The Retroactive Funding process and algorithm ideally improves with each\n   round via governance feedback.\n * We’ve essentially audited RetroPGF Round 3. We did so through a cryptographic\n   proof, and anyone can verify it using this webapp\n   [https://retrofunding.ezkl.xyz/].\n * This paves the way for an end-to-end automated process with private voting,\n   checks and balances on the allocation algorithm, and smart contract enabled\n   allocation delivery.\n\nFor stakeholders, this audit means many things:\n\n * For badgeholders, that your vote was fairly counted\n * For recipients, that your allocation was fairly calculated\n * For everyone else, the results actually correspond with the Optimism\n   governance forums\n\n\nAN ITERATIVE APPROACH\n\nAs this forum is aware, a core tenet of the Optimism community is agile\niteration. That means the design of Round 3 looks much different from that of\nRound 1. We see that Round 3 heavily indexes on the impact evaluation framework,\nand as a both qualitative and quantitative measure, heavily relies on the\njudgement of voters (badgeholders).\n\nVotes are currently fed through an allocation algorithm, published publicly by\nthe Optimism team. The team announces the algorithm’s results at the conclusion\nof a round, as well as learnings to iterate upon for the next rounds.\n\nThe trickiest bit has always been effectively measuring impact. Reliance on\nquantitative metrics risks exclusion. Reliance of qualitative feedback risks\nhuman biases among other coordination challenges. And there are many more\ntradeoffs beyond these. Consequently, the algorithm and overarching design\ncontinues to evolve and evoke discussion. Ideally, we can check the process and\nalgorithm with each new iteration.\n\n\nTHE INTEGRITY CHALLENGE\n\nOne of the main tradeoffs for Retroactive Funding is related to privacy.\n\nFor such a large pool of OP rewards, transparency is important. We want to\nensure results are aligned with previous governance decisions. More importantly,\nthis recognizes that many projects depend on the allocation for sustainability.\n\nHowever, badgeholder votes are private in Retroactive Funding. A longstanding\nfeature of voting systems, this allows voters to express their true preferences\nwithout fear of retaliation, coercion, or pressure from others. It makes it\ndifficult to execute vote buying, and encourages honest participation.\n\nThis presents a key challenge: verifying that allocation outcomes are truly\nbased on badgeholder votes. Even though the allocation algorithm is public (and\nwe can check that it accurately codifies forum promises), we can’t run a check\nwithout the input data. In the worst case, we can’t guarantee that the provided\nallocation algorithm was even used or that all votes were counted.\n\n\nTHE ZERO KNOWLEDGE SOLUTION\n\nMaking this process transparent requires both a proof that legitimate votes were\ncounted and that the allocation algorithm was run as intended, whilst keeping\nthe votes themselves private. This is exactly the sort of proof zero-knowledge\n(ZK) cryptography was designed to enable — and why we’re so excited to showcase\nthis project as a hallmark use of the technology.\n\nThere are two places we apply ZKP:\n\n1. VERIFYING THE VOTING PROCESS\n\nThe first circuit verifies that the cast ballots are legitimate, and that all\nlegitimate ballots are counted. Ballots are legitimate if signed by a\nbadgeholder from the public whitelist.\n\nThe details:\n\n 1. Check the ballot signatures against the whitelist.\n 2. For each project, create a hash of all its legitimate ballots. This is\n    denoted as Hash A.\n 3. Aggregate the hashes to generate an overall proof. This proof means that\n    across all projects, all legitimate votes were counted.\n\nThis results in Proof A.\n\n2. CHECKING THE ALLOCATION ALGORITHM\n\nThe second circuit verifies the usage of the allocation algorithm.\n\nThe details:\n\n 1. For each project, we repeat steps 1 and 2 of the first circuit. This,\n    however, is denoted by Hash B. We will check that Hash A = Hash B out of\n    circuit.\n 2. Generate a proof over the allocation algorithm. The algorithm takes in a\n    ballot table as input, and outputs an allocation table. We only need one\n    proof of the whole algorithm.\n\nThe results in Proof B.\n\n3. COMBINING THE PROOFS\n\nSince we generate the proofs separately, we want to link them together\ncryptographically. This ensures there is not tampering of votes in between\nproofs. We link them by checking that the hashes of legitimate votes, Hash A and\nHash B, are the same. This is the same hash you see on the platform, just in QR\nform.\n\n4. VERIFYING A PROJECT’S ALLOCATION\n\nThis is where you come in! When you press verify, you check the allocation was\ncorrect for a given project.\n\nEven though the proofs are for all projects, each proof has a set of public\nvariables particular to a given project. In Proof A this is the hash of the\nvotes (Hash A), in Proof B this is the hash of the votes (Hash B) and the\nallocation amount for a given project.\n\nIf we change any of those variables, we break verification for a particular\nproject. Try it yourself!\n\n5. VERIFYING THE ENTIRE RETROPGF\n\nIt’s also possible to verify the entire RetroPGF round at once. You can do so by\npressing “verify” on the landing page.\n\n\nEVERYONE’S VERIFICATION MATTERS\n\nIf you’re neither a badgeholder nor a recipient, why hit the verify button?\nSimply put, verifying the results of the round contributes to the security and\nlegitimacy of the process.\n\nHere’s the idea: Blockchains have both social consensus (which fork is the main\none, which client should be run, etc.) and computational consensus. A smart\ncontract can enforce a set of rules, but humans decide which copy of the smart\ncontract is the canonical one. Election workers count ballots, but citizens\nrecognize the result. Similarly, by verifying the RetroPGF results for one or\nmore projects, you help solidify the social consensus around the legitimacy of\nthe vote. You are an election observer, contributing to a successful audit.\n\nphoto_2024-03-27_19-22-21 [https://hackmd.io/_uploads/ByUUpr4yR.jpg]\n\n\nIMPLEMENTATION DETAILS\n\nYou can find the code for this on our blog [https://blog.ezkl.xyz/post/zkrpgf/].\nWe briefly discuss the details for verification of the allocation algorithm.\n\nOptimism’s allocation algorithm was written in Python, which made the EZKL\npython library a natural fit for in-program conversion of the data science into\nzero-knowledge proofs. You’ll also notice that OP allocation votes are cast with\nfloating point amounts — this meant a very low tolerance for imprecision.\n\nEZKL already optimizes heavily for precision given the frequency of nonlinear\noperations (reciprocals, softmax, etc.) in data science and machine learning\nmodels. However, we also made substantial improvements to the core engine, and\nspecifically how we perform lookups, in order to retain proof size while\nincreasing numerical accuracy. Incidentally, proving performance for other\nmodels like random forests and transformers improved significantly (sometimes\nover 90%). A win-win!\n\nThere are a few more important details, specifically around signature\nverification and the proving system. This may require some background in\ncryptography, so we omit a full discussion here. However, this also is available\non our blog.\n\n\nNEXT STEPS\n\nThis is just the first step in auditing and automating the Retroactive Funding\nprocess. In the future, it is possible to create more comprehensive systems and\neven automate the process end-to-end. This may look something like:\n\n * Algorithm implemented and formally verified against specifications in\n   governance forums\n * Votes checked against whitelist of badgeholders via a proof of legitimacy\n * Upon verification, votes run through the allocation algorithm\n * Final allocation checked via a proof of calculation\n * Upon final verification, distribution of funds automatically\n\nThis also makes it easier to reflect and analyze voter behavior without\nrevealing information about any one badgeholder — facilitating incremental\nimprovement for the next round.\n\n\nOPEN QUESTIONS & CALL FOR FEEDBACK\n\nWe would be grateful for any feedback on the platform, and will aim to implement\nimprovements for future rounds. In particular:\n\n * Were you more interested in the verification of the whole RetroPGF or focus\n   on particular projects?\n * Did you find features like the ability to manipulate the hash or allocation\n   amount interesting? Did they make the meaning of the proof more clear?\n * Do you feel comfortable with the implementation, or should we provide further\n   details?\n * Are there additional aspects of the voting and allocation process where you\n   would like to see this applied? For example:\n   * Verifying data analysis on votes/results\n   * Verifying algorithms to select badgeholders or legitimate voters\n   * Verifying the weight / inclusion of certain impact metrics\n   * And any other ideas you may have!\n\nWe look forward to feedback and further discussion!",
  "views": 458,
  "like_count": 7,
  "word_count": 1485,
  "answer": [],
  "created_at": "2024-04-03T16:46:55.311Z"
}